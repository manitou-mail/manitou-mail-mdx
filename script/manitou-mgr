#!/usr/bin/perl

# manitou-mgr
# Copyright (C) 2004-2012 Daniel Verite

# This file is part of Manitou-Mail (see http://www.manitou-mail.org)
# v1.3.0

# This program is free software; you can redistribute it and/or modify
# it under the terms of the GNU General Public License version 2 as
# published by the Free Software Foundation.

# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.

# You should have received a copy of the GNU General Public License
# along with this program; if not, write to the Free Software
# Foundation, Inc., 59 Temple Place - Suite 330,
# Boston, MA 02111-1307, USA.

#####################################################################
# manitou-mgr
# Manitou-Mail manager (toolbox)
#####################################################################

use strict;

use DBI;
use DBD::Pg qw(:pg_types);
use IO::Handle;
use Getopt::Long;
use Encode;
use Digest::SHA1;
use Socket;
use POSIX qw(WNOHANG EWOULDBLOCK);

use Data::Dumper;
use Time::HiRes qw(gettimeofday tv_interval);

use Manitou::Words qw(load_stopwords index_words flush_word_vectors clear_word_vectors search);
use Manitou::Config qw(readconf getconf getconf_bool);
use Manitou::Encoding qw(encode_dbtxt decode_dbtxt);
use Manitou::Schema;
use Manitou::Attachments;

my $VERSION="1.3.0";

my $dbh;
my $cnx_string;

my $conf_file;
my $opt_quiet;
my %opt_action;

# Needed to execute CREATE DATABASE
my $opt_dbsuperuser;
my $default_dbsuperuser="postgres";
my $opt_dbsuperpassword;

my $opt_dbuser;
my $default_dbuser="manitou";
my $opt_dbname;
my $default_dbname="manitou";
my $opt_dbpassword;

my ($opt_dbhost, $opt_dbport);
my $opt_dry_run;

my $opt_reindex_step;
my $opt_reindex_begin;
my $opt_reindex_end;
my $opt_reindex_parts;
my $opt_reindex_jobs;
#my $opt_search_terms;

sub usage {
  my $p="[--conf=/path/to/config_file] [--quiet]";
  print STDERR qq~Usage:
  $0 --help
  $0 --version
  $0 --create-database [--db-name=db] [--db-user=user] [--db-super-user=superuser] [--db-super-password=passwd] [--db-host=dbhost] [--db-port=dbport] $p
  $0 --create-schema [--db-name=db] [--db-user=user] [--db-host=dbhost] [--db-port=dbport] [--dry-run] [--quiet] $p
  $0 --upgrade-schema [--dry-run] [--quiet] $p
  $0 --hash-attachments $p
  $0 --merge-attachments $p
  $0 --print-size $p
  $0 --clear-full-text-index $p
  $0 --reindex-full-text [--reindex-partitions=first[-last]] [--reindex-jobs=jobs] $p
~;
};

STDOUT->autoflush(1);

my $rc = GetOptions("conf:s" => \$conf_file,
#		    "search:s" => \$opt_search_terms,
		    "quiet" => \$opt_quiet,
		    "help" => \$opt_action{'help'},
		    "version" => \$opt_action{'version'},
		    "db-name=s" => \$opt_dbname,
		    "db-user=s" => \$opt_dbuser,
		    "db-password=s" => \$opt_dbpassword,
		    "db-super-user=s" => \$opt_dbsuperuser,
		    "db-super-password=s" => \$opt_dbsuperpassword,
		    "db-host=s" => \$opt_dbhost,
		    "db-port=s" => \$opt_dbport,
		    "create-database" => \$opt_action{'create-database'},
		    "create-schema" => \$opt_action{'create-schema'},
		    "upgrade-schema" => \$opt_action{'upgrade-schema'},
		    "dry-run" => \$opt_dry_run,
		    "print-size" => \$opt_action{'print-size'},
		    "merge-attachments" => \$opt_action{'merge-attachments'},
		    "hash-attachments" => \$opt_action{'hash-attachments'},
		    "reindex-full-text" => \$opt_action{'reindex-words'},
		    "reindex-partitions=s" => \$opt_reindex_parts,
		    "reindex-jobs=i" => \$opt_reindex_jobs,
		    "clear-full-text-index" => \$opt_action{'clear-word-index'}
		   );

if (!$rc) {
  usage();
  exit(1);
}

if ($opt_action{"help"}) {
  usage();
  exit(0);
}
if ($opt_action{"version"}) {
  print "$0 (manitou-mail mdx manager) $VERSION\n";
  exit(0);
}

if (!defined $conf_file && -r "/etc/manitou-mdx.conf") {
  $conf_file="/etc/manitou-mdx.conf"; # default config file
}
if (defined $conf_file) {
  my %err;
  if (!readconf($conf_file, \%err)) {
    print STDERR "Error in config file: ", $err{msg}, "\n";
    exit 1;
  }
}

if ($opt_action{"hash-attachments"}) {
  Connect();
  hash_attachments();
}
elsif ($opt_action{"merge-attachments"}) {
  Connect();
  merge_attachments();
}
elsif ($opt_action{"print-size"}) {
  Connect();
  print_size();
}
elsif ($opt_action{"create-schema"}) {
  Connect();
  create_schema();
}
elsif ($opt_action{"upgrade-schema"}) {
  Connect();
  upgrade_schema();
}
elsif ($opt_action{"create-database"}) {
  create_database();
}
elsif ($opt_action{"reindex-words"}) {
  Connect();
  my %optr;
  $optr{'parts'}=$opt_reindex_parts if ($opt_reindex_parts ne "");
  $optr{'jobs'}=$opt_reindex_jobs if ($opt_reindex_jobs);
  reindex_words($dbh,\%optr);
  $dbh->disconnect;
}
elsif ($opt_action{"clear-word-index"}) {
  Connect();
  clear_word_index();
}
#elsif ($opt_action{"iwi-query"}) {
#  iwi_query($opt_search_terms);
#}
else {
  usage();
}
exit(0);

sub Connect {
  if (!$opt_action{"create-database"}  &&
#    (defined ($opt_dbname // $opt_dbuser // $opt_dbpassword //
#     $opt_dbsuperuser // $opt_dbsuperpassword // $opt_dbhost // $opt_dbport)))
      (defined($opt_dbname) || defined($opt_dbuser) || defined($opt_dbpassword) ||
       defined($opt_dbsuperuser) || defined($opt_dbsuperpassword) ||
       defined($opt_dbhost) || defined($opt_dbport)))
  {
    print STDERR "Options --db-* can only be used with the --create-database action.\nFor other actions, the connection parameters are taken from the configuration file (--conf option, defaulting to /etc/manitou-mdx.conf).\n";
    exit 1;
  }

  $cnx_string=getconf("db_connect_string");
  if (!defined $cnx_string) {
    die "Please define the db_connect_string parameter in the configuration file.";
  }
  $dbh = DBI->connect($cnx_string) or die "Can't connect: $DBI::errstr";
  $dbh->{PrintError}=0;
  $dbh->{RaiseError}=1;
  $dbh->{pg_auto_escape}=1;
  $dbh->{AutoCommit}=1;
  if ($opt_quiet) {
    $dbh->do("set client_min_messages to error");
  }
  Manitou::Encoding::get_db_encoding($dbh);
}

sub create_schema_part {
  foreach (@_) {
    if ($opt_dry_run) {
      print "$_;\n";
    }
    else {
      if (!$dbh->do($_)) {
	$dbh->rollback;
	die "Statement failed: $_\n" . $dbh->errstr ."\n";
      }
    }
  }
}

sub create_database {
  if ($opt_dry_run) {
    print STDERR "The --dry-run option is not available for database creation.";
    exit 1;
  }
  my $scnx_string = "user=" . (defined $opt_dbsuperuser ? $opt_dbsuperuser : $default_dbsuperuser);
  $scnx_string .= " password=$opt_dbsuperpassword" if (defined $opt_dbsuperpassword);
  $scnx_string .= " host=$opt_dbhost" if (defined $opt_dbhost);
  $scnx_string .= " port=$opt_dbport" if (defined $opt_dbport);
  my $dbh1=DBI->connect("dbi:Pg:$scnx_string") or die;
  $dbh1->{AutoCommit}=1;
  $dbh1->{RaiseError}=0;
  my $dbname = defined $opt_dbname ? $opt_dbname: $default_dbname;
  my $dbuser = defined $opt_dbuser ? $opt_dbuser : $default_dbuser;
  my $s1 = $dbh1->prepare("SELECT 1 FROM pg_user WHERE usename='$dbuser'");
  $s1->execute();
  if ($s1->fetchrow_array) {
    print "The database user $dbuser already exists.\n" unless ($opt_quiet);
  }
  else {
    $dbh1->do("CREATE USER $dbuser") or die $dbh1->errstr;
    print "Database user $dbuser created.\n" unless ($opt_quiet);
  }
  $s1->finish;

  my $s2 = $dbh1->prepare("SELECT 1 FROM pg_database WHERE datname='$dbname'");
  $s2->execute();
  if ($s2->fetchrow_array) {
    print STDERR "The database $dbname already exists.\nPlease check and drop the database before attempting to recreate, or choose another database name.\n";
    exit 1;
  }
  $s2->finish;
  $dbh1->do("CREATE DATABASE $dbname OWNER $dbuser") or die;
  print "Database $dbname created.\n" unless ($opt_quiet);
  if ($dbh1->{pg_server_version}/10000 >= 9) {
    # Since Pg 9.0, each large object has it own ACL, except that lo_unlink() is ever
    # only permitted to the object's owner. That's too restrictive for us; it would
    # mean that only the db owner can delete messages, so we stick to pre-9.0 mode.
    $dbh1->do("ALTER DATABASE $dbname SET lo_compat_privileges TO on") or die $dbh1->errstr;
  }
  $dbh1->disconnect;

  # Reconnect to the new database as a superuser
  $dbh1 = DBI->connect("dbi:Pg:$scnx_string dbname=$dbname") or die DBI->errstr;
  my @lang = $dbh1->selectrow_array("SELECT 1 FROM pg_language WHERE lanname='plpgsql'");
  if (!@lang) {
    $dbh1->do("CREATE LANGUAGE plpgsql") or die $dbh1->errstr;
  }
  $dbh1->do("SET SESSION AUTHORIZATION $dbuser") or die $dbh1->errstr;

  $dbh=$dbh1;
  create_schema();
  print "Database $dbname successfully created.\n" unless ($opt_quiet);
}

sub create_schema {
  $dbh->begin_work;
  $dbh->do("SET client_min_messages=warning");
  my @sequences=Manitou::Schema::create_sequence_statements();
  print "Creating sequences\n" unless ($opt_quiet);
  create_schema_part(@sequences);

  my @tables=Manitou::Schema::create_table_statements();
  print "Creating tables\n" unless ($opt_quiet);
  create_schema_part(@tables);

  my @functions=Manitou::Schema::create_function_statements();
  print "Creating functions\n" unless ($opt_quiet);
  create_schema_part(@functions);

  my @triggers=Manitou::Schema::create_trigger_statements();
  print "Creating triggers\n" unless ($opt_quiet);
  create_schema_part(@triggers);

  my @data=Manitou::Schema::create_data_statements();
  print "Inserting configuration data\n" unless ($opt_quiet);
  create_schema_part(@data);

  my $version=Manitou::Schema::current_version();
  my $query="INSERT INTO runtime_info(rt_key,rt_value) VALUES ('schema_version','$version')";
  if ($opt_dry_run) {
    print "$query;";
  }
  else {
    $dbh->do($query);
  }

  $dbh->commit;
}

sub upgrade_schema {
  $dbh->begin_work;
  $dbh->do("SET client_min_messages=warning");
  my $sth=$dbh->prepare("SELECT rt_value,current_database() FROM runtime_info WHERE rt_key='schema_version'");
  $sth->execute;
  my ($db_version,$db_name)=$sth->fetchrow_array;
  if (!defined $db_version) {
    print STDERR "Error: couldn't identify the database schema version with the runtime_info table\n";
    exit 1;
  }

  my @supported = Manitou::Schema::supported_versions();
  if (! grep( {$_ eq $db_version} @supported)) {
    print STDERR "Error; version $db_version not supported by manitou-mdx automatic upgrade: the database schema needs to be upgraded manually.\n";
    exit 1;
  }

  my $db_current = Manitou::Schema::current_version();
  if ($db_version eq $db_current) {
    print "Database $db_name is already at version $db_version\n" unless ($opt_quiet);
    return 1;
  }
  print "Upgrading $db_name from $db_version to $db_current\n" unless ($opt_quiet);
  my @stmt = Manitou::Schema::upgrade_schema_statements($dbh, $db_version, $db_current);
  eval {
    foreach (@stmt) {
      if ($opt_dry_run) {
	print "$_;\n";
      }
      else {
	$dbh->do($_);
      }
    }
  };
  if ($@) {
    print STDERR $@;
    $dbh->rollback;
    print STDERR "Schema upgrade aborted and rolled back due to failure (see errors above). Upgrade the schema manually (see documentation) or fix the problem and retry.\n";
    exit 1;
  }
  if ($db_version ne $db_current) {
    my $query="UPDATE runtime_info SET rt_value='$db_current' WHERE rt_key='schema_version'";
    if ($opt_dry_run) {
      print "$query;\n";
    }
    else {
      $dbh->do($query);
    }
  }
  $dbh->commit;
  if (@stmt>0) {
    print "Schema successfully upgraded to version $db_current\n" unless ($opt_quiet);
  }
  else {
    print "No schema change\n" unless ($opt_quiet);
  }
  return 1;
}

sub clear_word_index {
  $dbh->do("TRUNCATE TABLE words,inverted_word_index,tags_words");
}

# Reindex a partition (inverted_word_index.part_no) in a forked process.
# Several reindex jobs can run concurrently in different processes, each
# with its own db connection.
sub child_reindex {
  my ($cnx_string, $opt)=@_;
  my $dbh = DBI->connect($cnx_string) or die "Can't connect: $DBI::errstr";
  $dbh->{PrintError}=0;
  $dbh->{RaiseError}=1;
  $dbh->{AutoCommit}=1;

  child_reindex_words($dbh, $opt);
  $dbh->disconnect;
}

sub get_word_id_from_parent {
  my ($word_utf8, $ctxt) = @_;
  my $fh=$ctxt->{fh};
  print $fh "W$word_utf8\n";
  my $id=<$fh>;
  chomp $id;
  $id;
}

sub parent_command {
  my ($ctxt, $command)=@_;
  my $fh=$ctxt->{fh};
  print $fh "$command\n";
  my $ret=<$fh>;
  chomp $ret;
  $ret;
}

sub parallel_reindex_parts {
  my $dbh=shift;
  my $jobs=shift;
  my @parts=@_;

  my @childs;
  $dbh->{AutoCommit}=1;
  my $partsize = Manitou::Words::load_partsize($dbh);

  my $parent_end=0;
  my %hwords; # Words are in utf-8 in %hwords, contrary to Manitou::Words::index_words
  my $sth_w = $dbh->prepare("SELECT word_id FROM words WHERE wordtext=?");
  my $sth_n = $dbh->prepare("INSERT INTO words(word_id,wordtext) VALUES (nextval('seq_word_id'),?) RETURNING word_id");

  $dbh->begin_work;

  while (@parts>0 || @childs>0) {
    if (@childs<$jobs && @parts>0) {
      my $i=shift @parts;
      push @childs, spawn_reindex_job($partsize*$i, $partsize*($i+1)-1, $i);
    }

    my $pid;
    while (($pid=waitpid(-1, WNOHANG))>0) {
      my $o=0;
      for my $c (@childs) {
	if ($c->{pid} eq $pid) {
	  #print "reaped $c->{part_no}\n";
	  splice @childs, $o, 1;
	}
	$o++;
      }
    }

    my $bits;
    foreach (@childs) {
      # if (!defined $_->{fh}) { print "not defined for $_->{part_no}\n" };
      vec($bits, fileno($_->{fh}), 1)=1 if (defined $_->{fh});
    }
    my $found = select($bits, undef, undef, 1);

    if ($found>0) {
      for my $c (@childs) {
	next if (!defined $c->{fh});
	while (1) {
	  my $buf;
	  my $n=sysread($c->{fh}, $buf, 50);
	  if (!defined $n) { # no bytes available
	    last if ($!==POSIX::EWOULDBLOCK);
	    # Error
	    warn "Error on pipe with child $c->{part_no}: $!";
	    close $c->{fh};
	    $c->{fh}=undef;
	    last;
	  }
	  if ($n==0) { # end of file
	    close $c->{fh};
	    $c->{fh}=undef;
	    last;
	  }
	  else {
	    $c->{word} .= substr($buf,0,$n);
	    # if there's a newline, no need to sysread() again, since
	    # we got a complete command.
	    last if (substr($buf,$n-1,1) eq "\n");
	  }
	}
	my $w=$c->{word};
	if (index($w, "\n")>=0) {
	  $c->{word}=undef;
	  chomp $w;
	  if (substr($w, 0,1) eq "W") {
	    # command Wword: get word_id for 'word'
	    $w=substr($w,1);
	    #child $c->{part_no} queries for the word '$w'\n";
	    my $id=$hwords{$w};
	    if (!defined $id) {
	      $sth_w->execute($w);
	      ($id)=$sth_w->fetchrow_array;
	      if ($id) {
		$hwords{$w}=$id;
	      }
	      else {
		# insert it
		$sth_n->execute($w);
		($id) = $sth_n->fetchrow_array;
		$hwords{$w}=$id if ($id);
		die "Unable to get word_id of inserted word\n" if (!$id);
	      }
	    }
	    print {$c->{fh}} "$id\n";
	  } # W command
	  else {
	    # other commands
	    if ($w eq "F") {  # Flush command
	      $dbh->commit;
	      $dbh->begin_work;
	      print {$c->{fh}} "1\n";
	    }
	  }
	}
      }
    }
  }
  $dbh->commit;
}

# sub linux_mem_size {
#   my $r=`cat /proc/$$/status | grep '^VmSize:'`;
#   return $1 if ($r =~ /^VmSize:\s*(\d+)/);
#   undef;
# }


# This function is run by indexer child processes.
# Child process reindex all messages in order with mail_id between
# $opt->{begin} and $opt->{end}.
# (in practice, this range of IDs is limited to only one inverted index
# partition for better performance, but that's up to the caller).
# Returns the last processed mail_id

# The child process communicates with the parent through parent_command()
# and get_word_id_from_parent()
sub child_reindex_words {
  my ($dbh,$opt)=@_;
  my $cnt_print;

  print "Reindex of partition #$opt->{part_no} started\n" unless ($opt_quiet);
  load_stopwords($dbh);
  my $col_html = getconf_bool("index_words_html_parts") ? "bodyhtml":"null";
  my $where;
  my $partsize = Manitou::Words::load_partsize($dbh);
  my $min_id = $opt->{begin} ? int($opt->{begin}):0;
  my $next_min_id = $min_id;
  my $sthb = $dbh->prepare("SELECT bodytext,$col_html FROM body where mail_id=?");
  my $sthh = $dbh->prepare("SELECT lines FROM header where mail_id=?");
  my $end=0;
  my %extractors = Manitou::Attachments::text_extractors();
  my $idx_html = getconf_bool("index_words_html_parts");
  my ($mail_id,$sender);
  my %ctxt = (fh=>$opt->{fh});

  while (!$end) {
    $dbh->begin_work;

    my $s;
    my @cond;
    push @cond, "mail_id>=".$next_min_id if ($next_min_id>0);
    push @cond, "mail_id<=".int($opt->{end}) if ($opt->{end});
    $where = @cond>0 ? "WHERE ".join(" AND ", @cond) : "";
    $s=$dbh->prepare("SELECT mail_id FROM mail $where ORDER BY mail_id");
    $s->execute;

    my $count=0;
    $mail_id=0;
    if ($s->rows==0) {
      $end=1;
      last;
    }

    my $t0 = [gettimeofday];
    while (($mail_id,$sender)=$s->fetchrow_array) {
      if ($min_id<$mail_id) {
	$min_id=$mail_id;
      }
      $count++;
      $sthb->execute($mail_id);
      my ($body,$html)=$sthb->fetchrow_array;
      $sthh->execute($mail_id);
      my ($header)=$sthh->fetchrow_array;
      $body = decode_dbtxt($body);
      $header = decode_dbtxt($header);

      if ($sender =~ /^MAILER-DAEMON@/) {
	# Some SMTP servers (e.g. qmail) may send bounces that regurgitate the
	# entire original message in one big destructured piece,
	# possibly with encoded attachments that can't be recognized
	# as such for lack of a proper MIME structure.
	# As a workaround to avoid the vast pollution of the word index
	# that it may incur, we limit the indexing at 500 lines of text.
	my $nbl=500;
	my $pos=0;
	while (($nbl--)>0 && $pos>=0) {
	  $pos=index($body, "\n", $pos);
	  $pos++ unless ($pos==-1);
	}
	if ($nbl<0 && $pos>0) {
	  $body=substr($body, 0, $pos);
	}
      }

      my $other_words;
      if ($html) {
	$html = decode_dbtxt($html);
	$other_words = Manitou::Words::html_to_text(\$html);
      }
      $header = Manitou::Words::header_contents_to_ftidx($header);
      if (scalar(%extractors)!=0 || ($idx_html && length($html)>0)) {
	Manitou::Attachments::launch_text_extractors($dbh, $mail_id,
						     \%extractors,
						     \$other_words);
      }
      index_words($dbh, $mail_id, \$body, \$header, \$other_words,
		  \&get_word_id_from_parent, \%ctxt);

    }

    if (!parent_command(\%ctxt, "F")) {
      print "Warning: words buffer flush not acknowledged by parent\n" unless ($opt_quiet);
    }
    flush_word_vectors($dbh, {'no_jobs_queue'=>1});
    clear_word_vectors();
    $dbh->commit;
    my $tspent = int(tv_interval($t0));
    my $rate = int($tspent>0 ? $count/$tspent : 0);
    print "$count messages reindexed in partition #$opt->{part_no} (up to mail_id=$min_id, $rate messages/s)\n" unless ($opt_quiet);
    $next_min_id=$min_id+1;
  }
  return $min_id;
}

sub reindex_words {
  my ($dbh,$opt)=@_;
  my $partsize = Manitou::Words::load_partsize($dbh);
  my @parts;

  my $p=$opt->{parts};
  if (defined $p) {
    if ($p =~ /^(\d+)-(\d+)$/) {
      for ($1..$2) {
	push @parts, $_;
      }
    }
    elsif ($p =~ /^(\d+)$/) {
      push @parts, $1;
    }
    else {
      die "Unable to parse value for word index partitions range: $p";
    }
  }
  else {
    # If no partition is specified, reindex all of them.
    my $sth=$dbh->prepare("SELECT min(mail_id), max(mail_id) FROM mail");
    $sth->execute;
    {
      use integer;
      my @r=$sth->fetchrow_array;
      for (my $i=$r[0]/$partsize; $i<$r[1]/$partsize; $i++) {
	push @parts, $i;
      }
    }
  }

  $dbh->{InactiveDestroy}=1;
  parallel_reindex_parts($dbh, defined $opt->{jobs}?$opt->{jobs}:1, @parts);
}

# Spawn a child with parent-child communication through sockets
sub spawn_reindex_job {
  my ($id1,$id2,$part_no)=@_;
  my %r;
  my ($fhc,$fhp);

  socketpair($fhc, $fhp, AF_UNIX, SOCK_STREAM, PF_UNSPEC)
    or  die "socketpair: $!";
  $fhc->autoflush(1);
  $fhp->autoflush(1);
  my $pid=fork();
  if ($pid>0) {
    close $fhp;
    $fhc->blocking(0);
    $r{pid}=$pid;
    $r{fh}=$fhc;
    $r{part_no}=$part_no;
  }
  else {
    die "cannot fork: $!" unless defined $pid;
    close $fhc;
    $0 = "mail-reindex#$part_no";
    my %ctxt = (fh=>$fhp, begin=>$id1, end=>$id2, part_no=>$part_no);
    child_reindex(getconf("db_connect_string"), \%ctxt);
    close $fhp;
    exit(0);
  }

  return \%r;
}

sub hash_attachments {
  my $su=$dbh->prepare("UPDATE attachment_contents SET fingerprint=? WHERE attachment_id=?");
  my $sth=$dbh->prepare("SELECT attachment_id, content FROM attachment_contents WHERE fingerprint IS NULL LIMIT 1000");
  do {
    $dbh->begin_work;
    $sth->execute;
    my $sha1 = Digest::SHA1->new;
    while (my @r=$sth->fetchrow_array) {
      $sha1->reset;
      my $lobj_fd = $dbh->func ($r[1], $dbh->{pg_INV_READ}, 'lo_open');
      die $dbh->errstr if (!defined($lobj_fd));
      my $buf;
      my $nbytes;
      do {
	$nbytes = $dbh->func($lobj_fd, $buf, 16384*4, 'lo_read');
	$sha1->add($buf);
	die $dbh->errstr if (!defined $nbytes);
      } while ($nbytes==16384*4);
      $dbh->func ($lobj_fd, 'lo_close');
      my $b64=$sha1->b64digest;
      $su->execute($b64, $r[0]);
      printf("Updating attch_id=%d with hash '%s'\n", $r[0], $b64) unless ($opt_quiet);
    }
    $dbh->commit;
  } while ($sth->rows>0)
}

sub merge_attachments {
  my $sth=$dbh->prepare("SELECT fingerprint,MIN(content) FROM attachment_contents WHERE fingerprint IS NOT NULL GROUP BY fingerprint HAVING count(*)>1");
  my $sth1=$dbh->prepare("SELECT attachment_id, content FROM attachment_contents WHERE fingerprint=? AND content<>?");
  my $sthu=$dbh->prepare("UPDATE attachment_contents SET content=? WHERE attachment_id=?");
  $sth->execute;
  my %removed; # references to removed LOs
  $dbh->begin_work;
  while (my ($fingerprint,$keep_oid)=$sth->fetchrow_array) {
    $sth1->execute($fingerprint, $keep_oid);
    while (my ($id,$oid)=$sth1->fetchrow_array) {
      if (!exists $removed{$oid}) {
	if (!$dbh->func($oid, 'lo_unlink')) {
	  print "Warning: failed to remove large object $oid (attachment_id=$id)\n";
	}
	else {
	  print "Removed large object $oid\n" unless ($opt_quiet);
	  $removed{$oid}=1;
	}
      }
      $sthu->execute($keep_oid, $id);
    }
  }
  $dbh->commit;
}

sub print_size {
  my @tables=
    (
     "addresses",
     "attachment_contents",
     "attachments",
     "body",
     "header",
     "inverted_word_index",
     "mail",
     "mail_addresses",
     "mail_tags",
     "pg_largeobject",
     "raw_mail",
     "words");

  print "-"x35, "\n";
  my $sth1=$dbh->prepare("SELECT pg_total_relation_size(?)");
  foreach (@tables) {
    $sth1->execute($_);
    my ($sz)=$sth1->fetchrow_array;
    printf("%-20s: %8.2f MB\n", $_, $sz/(1024*1024));
  }

  print "-"x35, "\n";
  my $sth=$dbh->prepare("SELECT pg_size_pretty(pg_database_size(current_database()))");
  $sth->execute;
  my ($szb)=$sth->fetchrow_array;
  printf("Total database size : %s\n", $szb);
}

# sub iwi_query {
#   my $terms = shift;
#   die "A non-empty search query must be specified" if (length($terms)==0);
#   my @results = Manitou::Words::search($dbh, $terms);
#   print join(",", @results), "\n";
# }

__END__

=head1 NAME

 manitou-mgr - A management toolbox for Manitou-Mail

=head1 SYNOPSIS

  manitou-mgr --create-database [--db-name=db] [--db-user=user] [--db-super-user=superuser] [--db-super-password=passwd] [--db-host=dbhost] [--db-port=dbport] options
  manitou-mgr --create-schema [options]
  manitou-mgr --upgrade-schema [options]
  manitou-mgr --hash-attachments [options]
  manitou-mgr --merge-attachments [options]
  manitou-mgr --print-size [options]
  manitou-mgr --reindex-full-text [options] [--reindex-partitions=N[-M]] [--reindex-jobs=J]
  manitou-mgr --clear-full-text-index [options]

where options are: [--conf=/path/to/config_file] [--quiet]


=head1 DESCRIPTION

=over

=item B<create-database>:
 create a new PostgreSQL database with all the necessary objects to hold the mail data.

=item B<create-schema>:
 create all database objects to hold the mail data (should be applied to an empty database). Generally this is not needed since --create-database already creates the database objects.

=item B<upgrade-schema>:
 upgrade database objects to a newer version of manitou-mdx

=item B<print-size>:
 print the sizes on disk of the main database tables.

=item B<hash-attachments>:
 compute the fingerprints of the attachments in the database that have no fingerprint. This is done automatically by manitou-mdx during normal import so this option shouldn't be used except for troubleshooting.

=item B<merge-attachments>:
 merge attachments that share the same fingerprint. This is done automatically by manitou-mdx during normal import so this option shouldn't be used except for troubleshooting.

=item B<reindex-full-text>: [--reindex-partitions=N[-M]] [--reindex-jobs=J]
 rebuild the full text index. Optionally starts at partition I<N> and ends at I<M>, flushing the index to the database and reclaming memory at the end of every partition. Different partitions can be indexed in I<J> jobs in parallel.

=item B<clear-full-text-index>:
 clear the full text index by truncating the relevant SQL tables. This is recommended before a B<reindex-full-text> of the entire database.

=back

=head1 Database options

=over

=item B<--db-name>:
 Database name to create a new database (manitou by default).

=item B<--db-user>:
 Database user that will own a newly created database (manitou by default).

=item B<--db-host>:
 Database host name to connect to. By default, connect to a local database (by unix socket)

=item B<--db-port>:
 Database port number to connect to. By default, 5432.

=item B<--db-super-user>:
 Database superuser to create a new database (postgres by default)

=item B<--db-super-password>:
 Password of database superuser, empty by default.

=back

=head1 Database access permissions

=over

=item The default PostgreSQL configuration (pg_hba.conf file) is often such that the Unix postgres user can connect locally without a password as the postgres database superuser (authentication method: ident). This user has the necessary permissions to create a new database, a database user, and give ownership of the new database to that user. So under this default configuration, manitou-mgr --create-database may be run as the postgres unix user with no password. Once the manitou database and user are created, the connection information is read from the B<db_connect_string> entry of the configuration file that has to be filled in by the user.

=back

=cut
